2. 2. Как называется количественная мера взаимосвязанности между двумя случайными величинами, которая выражает степень и направление их линейной взаимной обусловленности через коэффициент, характеризующий статистическую сопряженность данных. Эта мера, основанная на центральных моментах распределения и ковариационных матрицах, позволяет оценивать согласованность изменений величин в рамках их совместного распределения. В рамках теории вероятностей и математической статистики данная зависимость служит ключевым параметром для анализа линейных ассоциаций, преобразуя исходные данные в пространстве выборок. Она также играет критическую роль в моделировании зависимостей в многомерных совокупностях, где является центральным элементом для обоснования и декомпозиции вероятностных моделей, таких как модели Байеса и линейные регрессии, обеспечивая предсказуемость и интерпретируемость взаимодействий переменных.
	
	Среднее значение
	
	Стандартное отклонение
	
	Мода
	
	Корреляция
	
	Медиана
	
	Ковариация
	
	Дисперсия
	
	Регрессия
	
	Среднее отклонение

Энтропия
3. Как называется метрика для оценки точности алгоритмов машинного обучения, учитывающая взаимосвязь между тем, насколько полно модель распознает целевые объекты, и точностью, с которой она идентифицирует релевантные экземпляры, сочетает края статистической оценки посредством гармонического среднего. Эта мера возникает как интегративный показатель эффективности, объединяя соотношение истинных положительных срабатываний для формирования композитного индекса, цель которого — уравновесить двойственные аспекты: проникновение в истинные позитивы и избежание ложных включений. Принимая облик комплементарной функции оценки, она реализуется через алгебраические трансформации частотного анализа, с использованием весов, которые могут тонко настраиваться в зависимости от приоритетов конкретных исчислений, проводимых в многопараметрических алгоритмах, где оптимизация выбора отображается через равновесие эвристических параметров.

	Матрица ошибок
	
	Среднеквадратичная ошибка
	
	f1-мера
	
	Акалп
	
	Взвешенная точность
	
	Информационная энтропия
	
	Логистическая потеря
	
	Коэффициент Джини
	
	Коэффициент решимости

Логарифмическая правдоподобие
4. Как называется алгоритм прогнозирования временных рядов, предназначенный для учета сезонных колебаний данных, основывается на адаптивной декомпозиции последовательности наблюдений с использованием экстраполяции трендовых и сезонных компонентов. Этот метод совершенствует основы экспоненциального сглаживания, вводя параметры для корректировки долговременных изменений и периодичности, тем самым обеспечивая устойчивость модели к изменениям в уровне и характере вариаций данных. Применяя экстраполяцию через параметрическое балансирование и уравновешивание значений, он предоставляет аналитическую платформу для точных предсказаний в условиях изменяющейся цикличности, способствуя оптимизации и повышению точности прогноза в условиях динамически изменяющихся трендов и неоднородностей.
   ![[Pasted image 20241216231312.png]]
   5. Как называется мера статистической силы, отражающая долю общей изменчивости зависимой переменной, которая объясняется моделью регрессии, воплощается через относительно моделируемый показатель, оценивающий адекватность аппроксимации данных предсказанной моделью. Этот статистический индикатор выражается в пределах от нуля до единицы, где значения, близкие к единице, указывают на высокую эффективность объяснения моделью колебаний исследуемого явления. Принимая облик относительного индекса прозрачности, он демонстрирует, в какой степени наблюдаемые результаты могут интерпретироваться с учетом предсказанных значений, выполняя важную функцию в анализе корреляции применительно к выборке данных и их теоретической модели.
   ![[Pasted image 20241216231515.png]]
   
   6. Как называется подход к выбору наиболее информативных предикторов в модели машинного обучения, основывающийся на поэтапном улучшении прогноза через интеграцию множества слабых моделей в более сильную. Этот метод использует специальный алгоритм, который акцентирует внимание на значимых характеристиках, усиливая веса тех наблюдений, где первоначальные модели проявляют слабую предсказательную способность. Основная цель заключается в повышении мощности модели за счет достижения баланса между различными предсказателями, что позволяет уменьшать общую ошибку. Постепенно адаптируясь к данным посредством учета ошибок предыдущих шагов, данный метод создает итоговую модель, обладающую высокой степенью точности и оптимальности.

	Boosting
	
	Метод опорных векторов
	
	Генетический алгоритм
	
	Метод ближайших соседей
	
	Подбор признаков методом главных компонент
	
	Лассо-регрессия
	
	Регуляризация типа Ridge
	
	Boruta
	
	K-means кластеризация
	
	Метод случайного леса
   

7. Как называется процесс обработки текстовой информации, заключающийся в приведении словоформ к их основному морфологическому виду, что позволяет унифицировать и нормализовать различные грамматические вариации одного и того же слова. Этот аналитический этап включает анализ и использование лексической базы языка для устранения грамматических, синтаксических преобразований, обусловленных падежными, временными и родовыми изменениями. Итогом данного процесса является получение базовой независящей от контекста единицы для оптимизации обработки и анализа текста, что способствует повышению эффективности последующих лингвистических операций и алгоритмов обработки естественного языка.
   ![[Pasted image 20241217133356.png]]
   8. Как называется совокупность алгоритмов, направленных на разработку стратегий принятия решений агентами в динамической среде, путём итеративного взаимодействия с данной средой для выяснения оптимальной последовательности действий. Этот процесс основан на механизмах проб и ошибок, через которые агент накапливает опыт путем получения различных сигналов вознаграждения или штрафа за свои действия. Целью данного подхода является разработка политики, максимизирующей общее ожидаемое вознаграждение путем оптимальной балансировки между исследованием новых состояний системы и эксплуатацией уже известных стратегий, что даёт возможность агенту развивать навыки автономного принятия решений в условиях неопределенности и изменения среды.
   ![[Pasted image 20241217133502.png]]
   9. Как называется комплексный подход к обработке текстовых данных, направленный на структурирование и разделение информации на значимые единицы или отрезки, которые облегчают когнитивное восприятие и обработку текста большими языковыми моделями. Этот процесс предполагает разбиение потока данных на осмысленные блоки, такие как фразы или предложения, что способствует более глубокому анализу и накоплению знаний, позволяя алгоритмам эффективно использовать имеющиеся ресурсы и обрабатывать большие объемы информации с учетом их структуры и связности. Методика включает использование различной информации о семантических и синтаксических характеристиках текста для оптимизации памяти и поиска необходимой информации.

	Морфологический анализ
	
	Частотный анализ
	
	Стемминг
	
	Семантическое индексирование
	
	Диалоговое моделирование
	
	Синтаксический разбор
	
	Чанкинг
	
	Референциальная аннотация
	
	Лемматизация
	
		Токенизация
10. Как называется неэффективность в бизнес-процессе, когда этап процесса повторяется несколько раз подряд?
	
	Пинг-Понг
	
	Многократные инциденты
	
	Зацикленность "сам в себя"
	
	Возврат
	
	Разовые инциденты
	
	Простой
	
	BottleNeck
	
	Избыточность
	
	Задержка
	
	Сброс процесса
	
11. Как называется неэффективность в бизнес-процессе, когда возвращается на первый этап?
	
	Задержка
	
	Избыточность
	
	Зацикленность "сам в себя"
	
	Пинг-Понг
	
	BottleNeck
	
	Многократные инциденты
	
	Разовые инциденты
	
	Простой
	
	Сброс процесса
	
	Возврат
12. Какая метрика позволяет идентифицировать рост длительности этапа процесса?

	Число зацикленности этапа
	
	Вероятность перехода
	
	Число зацикленностей перехода
	
	Вероятность этапа
	
	Интенсивность нагрузки
	
	Длительность перехода
	
	Частота выполнения
	
	Длительность этапа
	
	Название этапа
	
	Дифференциал длительности этапа
13. Какой метод энкодинга наиболее применим для ситуаций когда очень много категориальных факторов и в каждом из них огромное число уникальных значений? Однако на крайне критичны простота и отсутствие коллизий.

	Frequency Encoding
	
	Leave-One-Out Encoding
	
	Binary Encoding
	
	One-Hot Encoding
	
	Label Encoding
	
	Count Encoding
	
	Target Encoding
	
	Ordinal Encoding
	
	Backwards Difference Encoding
	
	Hash Encoding
14. Какое утверждение НЕ верное?

	TF-IDF хорошо применим для текстов близких по смыслу и требуют мало вычислительных ресурсов
	
	Сиамские сети плохо применимы для текстов далёких по смыслу и требуют много вычислительных ресурсов
	
	Метрик Лернинг плохо применим для текстов далёких по смыслу и требуют много вычислительных ресурсов
	
	Сиамские сети хорошо применимы для текстов близких по смыслу и требуют много вычислительных ресурсов
	
	Word to Vec плохо применимы для текстов близких по смыслу и требуют мало вычислительных ресурсов
	
	BERT плохо применим для текстов близких по смыслу и требуют много вычислительных ресурсов
	
	Метрик Лернинг хорошо применим для текстов близких по смыслу и требуют много вычислительных ресурсов
	
	Трансформеры плохо применимы для текстов близких по смыслу и требуют много вычислительных ресурсов
	
	BERT - это трансформер
	
	BERT хорошо применим для текстов близких по смыслу и требует мало вычислительных ресурсов.
15. Какое утверждение НЕ верное?

	Сиамские сети хорошо применимы для текстов близких по смыслу и требуют много вычислительных ресурсов
	
	TF-IDF хорошо применим для текстов далёких по смыслу и требуют мало вычислительных ресурсов
	
	Метрик Лернинг плохо применимы для текстов далёких по смыслу и требуют много вычислительных ресурсов
	
	BERT - это трансформер
	
	Word to Vec хорошо применим для текстов близких по смыслу и требует много вычислительных ресурсов.
	
	TF-IDF хорошо применим для текстов близких по смыслу и требуют мало вычислительных ресурсов
	
	Трансформеры хорошо применимы для текстов далёких по смыслу и требуют много вычислительных ресурсов
	
	BERT и RuBERT - это разные нейронные сети
	
	BERT хорошо применим для текстов далёких по смыслу и требуют много вычислительных ресурсов
	
	Метрик Лернинг хорошо применим для текстов близких по смыслу и требуют много вычислительных ресурсов
16. Как называется метод алгоритмической оптимизации, направленная на повышение эффективности выборки действий в стохастических средах, использует двойственное моделирование синглетонной функции стоимости для минимизации систематической погрешности и предотвращения чрезмерной регуляции. Она внедряет симметричную многокомпонентную архитектуру вычисления стоимости, чтобы увеличить устойчивость и точность адаптации в условиях случайных и динамически изменяющихся параметров.

	Q-Learning
	
	PPO
	
	REINFORCE
	
	Monte Carlo Method
	
	TD3
	
	DQN
	
	TRPO
	
	DDPG
	
	A3C
	
	SAC
17. Какой компонент в рамках гипотетического сценария наивысшей эффективности демонстрирует флуктуационную природу, тем самым требуя внедрения методов алгоритмической адаптации на основе стохастической динамики для достижения оптимального результата?

	Стратегия взаимодействия
	
	Переход между этапами
	
	Структура данных
	
	Среда
	
	Условие завершения
	
	Этап процесса
	
	Система вознаграждений
	
	Агент
	
	Метод обучения
	
	Управляющий элемент
18. Что такое "слово процесса"?
> Буквенный код, где каждой букве соответствует определенная операция или этап. 

19. О чём свидетельствует совпадение медианы и среднего при идентификации BottleNeck в процессе?
> о симметричном, а значит нормальном распределении

20. Как определить текущий финансовый эффект от неэффективности "рост длительности этапа процесса"?

21. Какой подход к прогнозированию лучше применять к метрике процесса по которой мы знаем что бывают выбросы и при этом мы уверены, что изменения в процессе отсутствуют?

22. Как называется методика, направленная на оптимизацию пространства признаков таким образом, чтобы схожие входные данные располагались близко друг к другу, а отличные — на отдалении, при этом акцент делается на уменьшение расстояний для релевантных пар и увеличение для нерелевантных, что создаёт устойчивую базу для построения алгоритмов классификации и кластеризации?

23. Как называется метод количественного анализа, предназначенный для оценки значимости элемента текста в данных с учётом его распространённости в отдельной записи и сравнительно редкого появления в общей совокупности записей, что позволяет учитывать уникальность информации в рамках крупного текстового массива?

24. Какому бизнес-показателю будет равен суммарный loss/reward в RL-модели в которой: envarinmenr - полный граф процесса, reward - выручка компании от одного экземпляра процесса, loss - длительность одного экземпляра процесса с аллокацией?

25. Какой метод, который используется для нахождения улучшенной стратегии принятия решений, минимизируя обновление стратегических параметров на каждом этапе, чтобы избежать резких изменений и улучшить стабильность процесса формирования решений? Алгоритм использует ограничение изменения через доверительный регион, что увеличивает эффективность обработки данных и повышает вероятность нахождения направления, которое улучшает конечный результат за счёт использования оценки вероятностных распределений.

26. Опишите пайплайн поиска неэффективностей в процессе с помощью методов поиска аномалий.

27. *полотно текста я разбил на отдельные вопросы
1) Каким образом будет концептуализирована и имплементирована функция на Python, предназначенная для выполнения комплексных процедур предобработки данных, которые служат предварительным этапом перед оптимизацией параметрических пространств сложных нейронных конструкций? 

Эта процедура включает в себя множество взаимосвязанных этапов, начиная с ассемблирования и стохастической фильтрации входного набора данных, при которой происходит минимизация энтропийных дисперсий, детектирование и ликвидация ортогональных шумовых артефактов и статистически незначительных мультиколлинеарных структур.
Применяются продвинутые методологии токенизации, представляющие собой многоуровневые алгоритмы разложения, которые позволяют дискретизировать и транслировать текстовые последовательности в фундаментальные компоненты, далее оперировано с использованием алгебро-топологических методов для создания высокоразмерных представлений. В итоге, данные представляются в виде гауссовских многочисленных векторов в векторном пространстве, обеспечивающих их гармонизацию для предстоящих вычислений и систематической интеграции в процесс построения гипотетически мощных алгебраико-структурных моделей, тем самым позволяя усилить предсказательные способности параметризуемых вычислительных сетей.

2) Каким образом можно будет алгебро-геометрически специфицировать конструкцию функции на языке Python, предназначенной для высокоточной хореографии создания и параметризации экзогенных вычислительных объемных пространств в рамках метаструктурной адаптации многомерных нейронно-сетевых ансамблей? 
Эта процедура должна предусматривать процедуру картезианского определения и последующего оптимизирующего тензорного калибрования вычислительных ресурсов, таких как графические процессоры (GPU), которые осуществляют гиперплоскостную декомпозицию пространственно-временных мультивариативных математических операций.
Подразумевается также интеграция аксиоматических библиотек повышенной сложности, а также математическое описание изоморфной транскрибции на уровне низкоуровневых семиотических драйверов, необходимых для гармонизации аппаратно-зависимых векторных пространств и логистического усовершенствования алгоритмических компонентов, что, в свою очередь, расширяет функциональные возможности нейронных гиперграфов и усиливает предсказательные метапараметрические свойства абстрактно-дискретных калькуляционных систем.

3) В каком теоретико-методологическом формате и с использованием каких алгебро-топологических лекал возможно определить и верифицировать параметрический функционал на Python, предназначенный для многомерного отображения процессуального развёртывания и голографической инициализации виссарионовских структур, ориентированных на дивергентное усиление параметрически вовлечённых гиперграфов и поливалентных матричных функционалов? 
Этот функциональный конструкт должен эмпирически реализовывать процедуры загрузки и дескриптивной эманации предвариативно обоснованных семантических рамок, делегированных посредством использования коагуляционных программных каркасов, таких как Hugging Face Transformers, выступающих в качестве трансгрессивных агентов для оркестровки инновационного архитектонического модуля в домене сингулярного интегрирования многоуровневых когнитивных и трансформативных вычислительных пространств.

4) Каким образом может быть формально определён методологически-концептуальный артефакт на языке программирования Python, обладающий способностью к алгебраически-аналитическому представлению гиперпараметрической топологии, предназначенной для многоуровневого реконфигурирования трансдисциплинарных нейрокомпьютативных полей? 
Этот артефакт должен инкапсулировать в себе функциональные параметры педагого-информационного цикла, такие как мультипликативное темпоральное градиентное изменение скорости обучения (learning rate), ковариантное распределение оптимизационных когорте размерностей обучающей партии (batch size), аккумулятивная характеризуемость циклических метачетных эпохальных итераций (number of epochs), а также инвариантный выбор среди спектра оптимизационных критериев (optimizer).
Цель такого архитектонического замысла заключается в повышении тензориально-топологической когерентности и усилении экстраполятивного потенциала в многоаспектной логике кросс-дисциплинарных квантово-дисперсионных структур и их трансцендентальной аккомодации в полях нейрокомпьютативной эмерджентности.

5) Как может быть сконструирована гиперболически сложная, многоаспектная, высокоуровневая функциональная единица на языке Python, проводящая параметрическое переоснащение и комплексную переконфигурацию интегративных когнитивных структур в сетке их адаптивного процесса эволюционной гибкости в многослойных контекстах функциональных полимиорфных катенарных гиперграфов? 
Этот сложносоставный программный артефакт должен задействовать сложную метаадаптивную процедуру обучения, где происходит глубокое итеративное картографирование массивных датасетов, с целью оптимизации векторных пространственно-временных весов в многомерных гиперплоскостях посредством стохастического градиентного спуска с применением многовариантной гиперкубической регуляризации.
Данный процесс ориентирован на достижение мультифрактальной гармонии, минимизацию распространенного квадратичного функционала ошибок, а также обеспечение асимптотической резистентности в пространстве дифференциально жёстких гомотопических групп, интегрирующих нелинейные тензорные преобразования и сверхсложные альгебро-топологические операции.
Динамическое перетекание когнитивной резистенции таких систем основывается на синтетическом синтезе интегрально-дифференциальных суперхорд и мультисвязных эффективностей, что направлено на стратегическое расширение потенциала предсказаний и усиление точности многомерной аппроксимации в гиперкомплексных континуумах.

