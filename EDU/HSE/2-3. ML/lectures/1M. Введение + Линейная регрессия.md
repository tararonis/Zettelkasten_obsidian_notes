14:43     2024/01/17    
Tags: #st 
____
# Общие термины

## Определения
- Целевая переменная - то, что мы хотим предсказать. Класс, значение, бинарная переменная(1-0, да-нет)
- Объект - сущности с которыми мы работаем - клиенты, дома, фотографии и тд
- Признаки - характеристики объектов - количество комнат, пол, возраст, доход, количество лошадиных сил, год выпуска и тд 
- Обучающая выборка - все данные с известными ответами
- Функционал ошибки - функция, которая измеряет качество работы алгоритма (MSE and etc)
	- Функция потерь -  это функция, которая минимизируется в процессе обучения модели (тож самое только сбоку, хотя функционал ошибки может означать более широкое понятие, учитывающим теоретическую ошибку на всем пространстве данных)
- Обучение - процесс поиска оптимального алгоритма, подбор весов для минимизации ошибки в процессе обучения
- Метрика качества - метрика для оценки качества уже обученной модели, оценивает насколько хорошо модель предсказывает на новых для себя данных (RMSE)
  > 	иногда одна и та же функция используется как для ошибки так и для качества

- Параметры модели - коэф. описывающие модель, подбираются автоматически при обучении модели на тренировочных данных.
	- структура дерева
	- веса
- Гиперпараметры - коэф. модели влиящие на обучение
	- глубина дерева
	- коэф регуляризации
- Разреженные модели - модели, в которых часть весов равна нулю
## Схема решения стандартных задач машинного обучения
Обучение -> применение
Задача: подобрать и настроить модель чтобы максимализировать предсказание
## Типы задач мл
- Классификация
	Целевая переменная - **класс объекта**
	- бинарная классификация - пол, болен пациент
	- многоклассовая классификация
- Регрессия
	    Целевая переменная - **число**
- Кластеризация
        Нет целевой переменной. Задача - разбить объекты на множества с похожими признаками.
        Отличие от классификации - изначально неизвестно/неданы/незаданы классы и их число
## Типы обучения 
- С учителем (предсказывается значение целевой переменной)
	- Классификация
	- Регрессия
	- Ранжирование
	- Рекомендательные системы(Зависит от алгоритма)
- Без учителя (целевой переменной нет, не с чем сверять ответ)
	- Кластеризация
	- Снижение размерности
	- Поиск аномалий
	- Генерация (изображений, текстов и так далее)
	- Рекомендательные системы(Зависит от алгоритма)
- Обучение с подкрепление(больше для ДЛ)
![[Pasted image 20240117160035.png]]

## Переобучение
Может возникнуть из-за:
- избыточной сложности модели (большое количество весов)
- переобучение есть всегда, разница только в том, большое оно или небольшое. оно возникает, что мы всегда имеем ограниченную выборку, а не все-все возможные данные в мире
### Признаки
- Качество на обучающей выборке высокое, а на тестовой нет - значит модель подстроилась под данные
- Большое значение параметров(весов)
## Способы разбиения
- Отложенная выборка (held-out / hold-out set)
	 Данные разбиваются на тренировочную и тестовую выборки.
	 Оцениваем качество на тренировочной и на тестовых выборках.
> Pros: можно посмотреть как модель ведет себя на новых данных, сравнить качество на train and test чтобы понять не переобучилась ли модель

> Cons: Качество модели зависит от тех данных на которых обучалась, значения метрик сильно зависят от тестовых данных. Может не хватить данных для обучения, так как мы делим данные на два датасета и потом их нигде не используем. 
- Кросс-валидация
  ![[Pasted image 20240117163554.png]]
- Среднее значение полученных метрик / качество модели не привязано к разбиению
- В большинстве задач рекомендуется использовать от 3-5 блоков
- Большое стандартное отклонение может показывать, что модель переобучилась
- Стандартное отклонение (STD) - мера разброса данных или разнообразия значений. Равно корню из дисперсии. Дисперсия - средне квадратичная разница между каждым значением и средним значением данных.
  ![[Pasted image 20240117170523.png]]
  * Leave-one-out CV - оставляем 1 объект для тестирования, а обучаем модели на всех остальных
  * Leave-P-out - тож самое, только настраиваем P - количество объектов/наблюдений для тестирования 
## В разведочный анализ обычно включены:

- однофакторный анализ, то есть анализ каждого признака в отдельности (исследование признака на наличие пропусков, выбросов, некорректных значений, визуализация, кодирование и дальнейшая очистка признака)
- двухфакторный анализ: анализ влияния каждого признака в отдельности на целевую переменную (вычисление корреляций, построение графиков)
- конструирование новых признаков на основе имеющихся
- построение разноплановых визуализаций

# Линейная регрессия
> 

Линейная регрессия - это алгоритм вида
![[Pasted image 20240117195043.png]]
где w0..wn - веса, x1..xn - признаки объекта

Веса - параметры модели
Обучение - поиск оптимальных параметров

> Мы изначально предполагаем, что в данных есть линейная зависимость.
> Строим гиперплоскость и предполагаем, что данные/ответы лежат на этой гиперплоскости.

Еще один способ записи:

![[Pasted image 20240117200943.png]]
### Плюсы линейных моделей
- Легко интерпретировать
- Быстро обучаются

### Минусы
- Признаки независимы - т.е каждый признак вносит индивидуальный вклад в ответ / не учитывается взаимосвязь признаков при предсказании целевой переменной.
## Обучение линейной регрессии
Суть - минимизация среднеквадратичной ошибки
![[Pasted image 20240117201317.png]]
> Обучение любого алгоритма машинного обучения сводится к минимизации какого-то функционала. Чаще всего - это какой-то гладкий дифференцируемый функционал.
>В случае ЛР - функционал ошибки - среднеквадратичное отклонение

> Функционал - это функция, которая принимает на вход другую функцию

> Функция потерь применима к одному объекту, а функционал ошибки - это средняя сумма функций потерь по всей обучающей выборке.

>В такой простой задаче функция выпуклая хоть и находится в многомерном пространстве. Функция имеет один минимум - он и локальный и глобальный.
>Чтобы решить задачу нужно выразить градиент, приравнять его у нулю и выразить веса w. 

## Регуляризация
> Регулязатор - это функция, которая штрафует за большие веса у модели, кроме w0, так как должен остаться 1 коэффициент, который отображает масштаб целевой переменной в задаче.
![[Pasted image 20240119200639.png]]

- Пример регуляризированного функционала
![[Pasted image 20240119201118.png]]
### L1 (Lasso)
>сумма модулей всех весов модели

![[Pasted image 20240119200936.png]]
**Полезное свойство:**
> в результате обучения модели L1 регуляризатором происходит обнуление некоторых весов, т.е. *отбор признаков*
### L2 (Ridge)

>сумма квадратов всех весов модели
>![[Pasted image 20240119201013.png]]

## Теорема Каруша-Куна-Таккера
Если все функции, которые входят в нашу задачу условной оптимизации выпуклые, то ее решение эквивалентно минимизации функции Лагранжа.
![[Pasted image 20240119202515.png]]
## One-hot encoding // Dummy  encoding
Метод трансформации категориального признака - добавление к датесету новых числовых колонок по количеству категориальных признаков, где этот признак будет иметь значение 1 или 0 в зависимости от первоначальной категории объекта.
![[Pasted image 20240117205316.png]]
- Созданные колонки в сумме дадут единичный столбец -> существует линейная зависимость. Чтобы ее избежать 1 колонку обычно удаляют или создают на одну меньше( ¯\_(ツ)_/¯ )

## Бинаризация
Разбить данные на бины и аналогично для каждого бина создать новый признак.
![[Pasted image 20240117205838.png]]
## Метрики качества
> Когда говорят функции потерь и функционал ошибки - говорят про то, что мы будем минимизировать во время обучения модели.
> Метрики качества - метрику которую мы замеряем когда обучили алгоритм.

> Все функции потерь в классическом машинном обучении выпуклые
### MSE (Mean squared error) 
> Среднеквадратичное отклонение

![[Pasted image 20240117212837.png]]
Минусы:
- Плохо интерпретируются - не сохраняет единицы измерения(так как возводит в ^2 - что такое кг^2)
- тяжело понять качество без понимания задачи
### RMSE (Root Mean squared error)
> Корень из среднеквадратичный ошибки
Снимает проблему с единицами измерения в MSE
![[Pasted image 20240117213424.png]]
### R2 (коэффициент детерминации)
> *долю дисперсии целевой переменной, объясняемую моделью*

![[Pasted image 20240119210528.png]]
> в знаменатели стоит константа, в числите MSE

Зависимость:
- Для идеальной модели, когда MSE = 0 -> R^2 = 1 
- Чем хуже модель, тем меньше R^2
![[Pasted image 20240119210829.png]]
### MAE (mean absolute error)
>средняя абсолютная ошибка

![[Pasted image 20240119210954.png]]
* более устройчива к выбросам чем MSE
### MAPE (mean average percentage error)
>средняя абсолютная процентная ошибка

![[Pasted image 20240119211349.png]]
проблема в том, что она несимметричная - т.е метрика штрафует больше за перепрогноз чем занижение прогноза.

### SMAPE (symmetric mean average percentage error)
>симметричная средняя абсолютная процентная ошибка

![[Pasted image 20240119211757.png]]
но чем сложнее метрика - тем хуже интерпретируется -> на практике редко используется

____
### Zero-Links
[[00 ML]]

____
### Links
[[Linear Regression]]
Запись занятия 
https://www.youtube.com/watch?v=o5o7zcJ2vAQ&list=PLmA-1xX7IuzCglOyTkTZ_bBHKd8eUr8pC&index=2&t=3093s&ab_channel=%D0%9C%D0%9E%D0%B8%D0%92%D0%A1%D0%9D%D0%98%D0%A3%D0%92%D0%A8%D0%AD
Stepik
https://stepik.org/lesson/806463/?unit=809639 
Git
https://github.com/hse-mlds/ml/tree/main/base_group/lesson_01

