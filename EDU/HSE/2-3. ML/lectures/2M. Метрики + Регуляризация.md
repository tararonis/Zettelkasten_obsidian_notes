15:23     2024/01/20    
Tags: #st #todo  
____
## Оптимумы MSE and MAE
> что это?

### Теорема
Дано множество l объектов с одинаковыми признаками, но разными значениями целевой переменной y.
> пример: продажа одного и того же автомобиля с разной ценой, клик на рекламный баннер одного и того же человека.

Тогда:
1. Оптимум MSE = среднему значению ответов
2. Оптимум MAE = медиане ответов

## MSLE (Mean Squared Logarithmic Error)
> среднеквадратичная логарифмическая ошибка

![[Pasted image 20240120153010.png]]
применяется когда предсказываем очень большие величины и нам не так важно, когда модель ошибется незначительно(но не хотелось бы чтобы модель ошибалась на порядок)

- подходит для задач с неотрицательной целевой переменной
- штрафует за отклонение в порядке величин
- штрафует заниженные прогнозы сильнее чем завешенные

> на практике самые используемые метрики в задаче регрессии - это MSE and MAE (**для функционала ошибки**)

> Для замерки качества еще используют R^2

### Вывод из части про метрики
1. MSE - mean squared error
   часто используют в качестве функционала ошибки, но он неустойчив к выбросам
2. MAE лучше работает, когда в данных много выбросов
3. R^2 может хорошо объяснить работу модели 
## Регуляризация
> Способ борьбы с переобучением

![[Pasted image 20240120230028.png]]
"Мы хотим минимизировать тот же функционал, что минимализировали раньше, но не хотим чтобы веса по норме росли вверх"
альфа - гиперпараметр
w1 - самма моделей, w2 - сумма квадратов весов

вес wo нельзя добавлять в регулязатор - от отвечает за смещение по оси ординат.


____
### Zero-Links
[[_Metrics]]
____
### Links
[[1M. Введение + Линейная регрессия]]