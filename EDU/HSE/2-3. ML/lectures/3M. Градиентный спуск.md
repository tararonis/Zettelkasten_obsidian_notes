23:41     2024/01/20    
Tags: #st
____
 Обучение модели состоит из подбора оптимальных значений весов исходя из минимизации ошибки.

Задачу минимизации можно решить 3 способами:
- подбор параметров вручную -> не подходит, так как порой у моделей Оочень много параметров и замучаешься их подбирать
- Аналитический -> самый точный, но не все задачи можно решить
- Численные методы -> наш универсальный бро

## Градиент
>_**градиент показывает направление наискорейшего роста функции**

т.е если нам нужно найти минимум -> выбираем направление противоположное градиенту, антиградиент

Алгоритм поиска градиента:
- выбираем произвольную точку
- на каждом шаге вычисляем градиент и сдвигаемся в точке противоположной градиенту
![[Pasted image 20240121000023.png]]
### Задачка
![[Pasted image 20240127194252.png]]
```
x1 = x0 - n * gr F (x0)
x1 = 1 - 0.1 * (2*x - 1) = 0.9
```

### Градиентный шаг (learning rate)
> задает скорость, с которой мы двигаемся в сторону min

- если он слишком большой - можем перепрыгнуть
- если слишком маленький - долго будем искать
### Критерии останова
> когда останавливать градиентный спуск?

- если **вектор весов** не изменился(практически) на соседних итерациях
  ![[Pasted image 20240127194942.png]]
- если значения **функции потерь п**рактически не изменились
  ![[Pasted image 20240127194953.png]]
- если **градиент равен нулю**(практически)
  ![[Pasted image 20240127195026.png]]
* если достигли оговоренного количества иттераций(мыж не можем искать вечно)


____
### Zero-Links
[[00 ML]]
____
### Links
[[2M. Метрики + Регуляризация]]